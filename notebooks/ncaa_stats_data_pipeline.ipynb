{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCAA Stats Data Pipeline\n",
    "\n",
    "This \"pipeline\" is a notebook used to setup NCAA data in our Databricks sandbox. It's largely used as a workaround since we don't have access to DLT/jobs in our sandbox environment; For now, I'll just run the scripts manually like a peasant, but in real-life this could be converted to\n",
    "DLT pipelines, jobs, etc\n",
    "\n",
    "The steps in this notebook:\n",
    "1. Setup the initial schema for landing NCAA data\n",
    "1. Load raw data into Databricks\n",
    "1. Run ETL scripts to cleanup and transform data into a format suitable for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run cells in this section to get your environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup module autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables using dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session for the Databricks compute environment\n",
    "from pyspark.sql import SparkSession\n",
    "from ncaa_tournament_predictor.config import Config\n",
    "from ncaa_tournament_predictor.databricks import get_databricks_spark_session\n",
    "\n",
    "# Explicit typing as SparkSession here to help out intellisense...DatabricksSession intellisense\n",
    "# isn't very good. In all my exploration so far, the DatabricksSession is compatible with the SparkSession\n",
    "spark: SparkSession = get_databricks_spark_session(Config.databricks_profile())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all cells above this one to setup your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Setup\n",
    "\n",
    "Initial steps to create a Databricks schema for holding NCAA mens basketball data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the ncaa_mens_basketball schema\n",
    "spark.sql(\"create schema if not exists object_computing.ncaa_mens_basketball;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Volumes\n",
    "Setup volumes for holding raw data files from various external data sources (CSVs, text files, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a volume for raw Kaggle stats data\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "raw_kaggle_stats_sql_object = volumes.as_sql_object(volumes.raw_kaggle_stats)\n",
    "spark.sql(f\"create volume if not exists {raw_kaggle_stats_sql_object}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy raw data into the raw_kaggle_stats volume\n",
    "\n",
    "import os\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "notebook_dir = os.path.abspath(os.getcwd())\n",
    "kaggle_dataset_path = os.path.abspath(\n",
    "    os.path.join(notebook_dir, \"../datasets/kaggle_ncaa_stats\")\n",
    ")\n",
    "\n",
    "for filename in os.listdir(kaggle_dataset_path):\n",
    "    spark.copyFromLocalToFs(\n",
    "        local_path=os.path.join(kaggle_dataset_path, filename),\n",
    "        dest_path=os.path.join(volumes.without_dbfs_protocol(volumes.raw_kaggle_stats), filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Kaggle stats dataset\n",
    "from ncaa_tournament_predictor import transformation, volumes\n",
    "\n",
    "raw_kaggle_stats = (\n",
    "    spark.read.format(\"csv\")\n",
    "        .options(header=True, inferSchema=True, mergeSchema=True)\n",
    "        .load(volumes.raw_kaggle_stats)\n",
    ")\n",
    "cleaned_ncaa_data = transformation.get_cleaned_kaggle_stats(raw_kaggle_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a volume for raw head-to-head data\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "spark.sql(f\"create volume if not exists {volumes.as_sql_object(volumes.raw_head_to_head)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy raw data into the raw_head_to_head volume\n",
    "\n",
    "import os\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "notebook_dir = os.path.abspath(os.getcwd())\n",
    "head_to_head_dataset_path = os.path.abspath(\n",
    "    os.path.join(notebook_dir, \"../datasets/kenpom_head_to_head\")\n",
    ")\n",
    "\n",
    "for filename in os.listdir(head_to_head_dataset_path):\n",
    "    spark.copyFromLocalToFs(\n",
    "        local_path=os.path.join(head_to_head_dataset_path, filename),\n",
    "        dest_path=os.path.join(volumes.without_dbfs_protocol(volumes.raw_head_to_head), filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup & Transformation\n",
    "Process the raw data, clean it up, and transform it for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/27 15:17:13 INFO mlflow.utils.credentials: Successfully connected to MLflow hosted tracking server! Host: https://dbc-6ec5c610-07d0.cloud.databricks.com.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3735c8c3a3944938a52d7d208c4ae056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ddd31ec37643519842ce24ef3bd331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ad6c6bb49a4914a4a25924199b1939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305674ce78964e84a7acaf3d9dfa52bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2802d2b12ec4b01a0a76411a9a30625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a027efe3074df19751d6dd60ea3f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/27 15:17:26 INFO databricks.ml_features._compute_client._compute_client: Setting columns ['team', 'college_season'] of table 'object_computing.ncaa_mens_basketball.game_prediction_features' to NOT NULL.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5fa498ff6845eca547df3c183aedb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5776964c7b924c94871fa17a577f7f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/27 15:17:29 INFO databricks.ml_features._compute_client._compute_client: Setting Primary Keys constraint ['team', 'college_season'] on table 'object_computing.ncaa_mens_basketball.game_prediction_features'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8b7951dea14596b294697e1a25113d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MlflowException",
     "evalue": "Reading Databricks credential configuration failed with MLflow tracking URI 'None'. Please ensure that the 'databricks-sdk' PyPI library is installed, the tracking URI is set correctly, and Databricks authentication is properly configured. The tracking URI can be either 'databricks' (using 'DEFAULT' authentication profile) or 'databricks://{profile}'. You can configure Databricks authentication in several ways, for example by specifying environment variables (e.g. DATABRICKS_HOST + DATABRICKS_TOKEN) or logging in using 'databricks auth login'. \nFor details on configuring Databricks authentication, please refer to 'https://docs.databricks.com/en/dev-tools/auth/index.html#unified-auth'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m mlflow.tracking._model_registry.utils._get_registry_uri_from_spark_session = \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[33m\"\u001b[39m\u001b[33mdatabricks-uc\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m mlflow.login()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mkaggle_stats\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/src/ncaa_tournament_predictor/jobs/kaggle_stats/__init__.py:32\u001b[39m, in \u001b[36mrun_job\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     30\u001b[39m spark = databricks.get_databricks_spark_session()\n\u001b[32m     31\u001b[39m write_cleaned_kaggle_stats(spark)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mconvert_cleaned_kaggle_stats_to_feature_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspark\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/src/ncaa_tournament_predictor/jobs/kaggle_stats/__init__.py:22\u001b[39m, in \u001b[36mconvert_cleaned_kaggle_stats_to_feature_store\u001b[39m\u001b[34m(spark)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_cleaned_kaggle_stats_to_feature_store\u001b[39m(spark: SparkSession):\n\u001b[32m     21\u001b[39m     fe_client = FeatureEngineeringClient()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[43mfe_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtables\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgame_prediction_feature_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtables\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcleaned_kaggle_stats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprimary_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mteam\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcollege_season\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/.venvs/databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster/lib/python3.12/site-packages/databricks/feature_engineering/client.py:357\u001b[39m, in \u001b[36mFeatureEngineeringClient.create_table\u001b[39m\u001b[34m(self, name, primary_keys, df, timeseries_column, partition_columns, schema, description, tags, **kwargs)\u001b[39m\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    347\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTimeseries column \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeseries_column\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not in primary_keys. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    348\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTimeseries columns must be primary keys.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    349\u001b[39m     )\n\u001b[32m    351\u001b[39m name = uc_utils.get_full_table_name(\n\u001b[32m    352\u001b[39m     name,\n\u001b[32m    353\u001b[39m     \u001b[38;5;28mself\u001b[39m._spark_client.get_current_catalog(),\n\u001b[32m    354\u001b[39m     \u001b[38;5;28mself\u001b[39m._spark_client.get_current_database(),\n\u001b[32m    355\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprimary_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprimary_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimestamp_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeseries_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFEATURE_ENGINEERING_CLIENT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/.venvs/databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster/lib/python3.12/site-packages/databricks/ml_features/_compute_client/_compute_client.py:108\u001b[39m, in \u001b[36mComputeClient.create_table\u001b[39m\u001b[34m(self, name, primary_keys, df, timestamp_keys, partition_columns, schema, description, tags, client_name, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPath argument is not supported for Unity Catalog tables.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    106\u001b[39m validation_utils.check_kwargs_empty(kwargs, \u001b[33m\"\u001b[39m\u001b[33mcreate_table\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprimary_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimestamp_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimestamp_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreq_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRequestContext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCREATE_TABLE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_name\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/.venvs/databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster/lib/python3.12/site-packages/databricks/ml_features/_compute_client/_compute_client.py:281\u001b[39m, in \u001b[36mComputeClient._create_table\u001b[39m\u001b[34m(self, name, primary_keys, df, timestamp_keys, partition_columns, schema, description, path, tags, req_context)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    279\u001b[39m     \u001b[38;5;66;03m# Delete empty Delta table.  The feature table will have already been cleaned up from the catalog.\u001b[39;00m\n\u001b[32m    280\u001b[39m     \u001b[38;5;28mself\u001b[39m._spark_client.delete_empty_table(name)\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# 4. Write to Delta table\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/.venvs/databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster/lib/python3.12/site-packages/databricks/ml_features/_compute_client/_compute_client.py:267\u001b[39m, in \u001b[36mComputeClient._create_table\u001b[39m\u001b[34m(self, name, primary_keys, df, timestamp_keys, partition_columns, schema, description, path, tags, req_context)\u001b[39m\n\u001b[32m    259\u001b[39m feature_key_specs = \u001b[38;5;28mself\u001b[39m._get_feature_key_specs(\n\u001b[32m    260\u001b[39m     delta_schema,\n\u001b[32m    261\u001b[39m     primary_keys_as_list,\n\u001b[32m    262\u001b[39m     timestamp_keys_as_list,\n\u001b[32m    263\u001b[39m     partition_cols_as_list,\n\u001b[32m    264\u001b[39m )\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_feature_table_with_features_and_tags\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpartition_key_specs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_key_specs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprimary_key_specs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprimary_key_specs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimestamp_key_specs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimestamp_key_specs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_uc_table\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_imported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_key_specs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_key_specs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreq_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    279\u001b[39m     \u001b[38;5;66;03m# Delete empty Delta table.  The feature table will have already been cleaned up from the catalog.\u001b[39;00m\n\u001b[32m    280\u001b[39m     \u001b[38;5;28mself\u001b[39m._spark_client.delete_empty_table(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/.venvs/databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster/lib/python3.12/site-packages/databricks/ml_features/_compute_client/_compute_client.py:1151\u001b[39m, in \u001b[36mComputeClient._create_feature_table_with_features_and_tags\u001b[39m\u001b[34m(self, name, partition_key_specs, primary_key_specs, timestamp_key_specs, feature_key_specs, is_imported, tags, description, req_context)\u001b[39m\n\u001b[32m   1149\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature_table:\n\u001b[32m   1150\u001b[39m     \u001b[38;5;28mself\u001b[39m._catalog_client.delete_feature_table(name, req_context)\n\u001b[32m-> \u001b[39m\u001b[32m1151\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/.venvs/databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster/lib/python3.12/site-packages/databricks/ml_features/_compute_client/_compute_client.py:1125\u001b[39m, in \u001b[36mComputeClient._create_feature_table_with_features_and_tags\u001b[39m\u001b[34m(self, name, partition_key_specs, primary_key_specs, timestamp_key_specs, feature_key_specs, is_imported, tags, description, req_context)\u001b[39m\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1123\u001b[39m     create_feature_table_req_context = req_context\n\u001b[32m-> \u001b[39m\u001b[32m1125\u001b[39m feature_table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_catalog_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_feature_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_key_spec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_key_specs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprimary_key_spec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprimary_key_specs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimestamp_key_spec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimestamp_key_specs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_imported\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_imported\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreq_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcreate_feature_table_req_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(feature_key_specs) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_uc_table:\n\u001b[32m   1135\u001b[39m     \u001b[38;5;28mself\u001b[39m._catalog_client.create_features(\n\u001b[32m   1136\u001b[39m         name, feature_key_specs, req_context\n\u001b[32m   1137\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/.venvs/databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster/lib/python3.12/site-packages/databricks/ml_features/_catalog_client/_catalog_client.py:223\u001b[39m, in \u001b[36mCatalogClient.create_feature_table\u001b[39m\u001b[34m(self, feature_table, partition_key_spec, primary_key_spec, timestamp_key_spec, description, is_imported, req_context)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_feature_table\u001b[39m(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    207\u001b[39m     feature_table: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    213\u001b[39m     req_context: RequestContext,\n\u001b[32m    214\u001b[39m ):\n\u001b[32m    215\u001b[39m     req_body = CreateFeatureTable(\n\u001b[32m    216\u001b[39m         name=reformat_full_table_name(feature_table),\n\u001b[32m    217\u001b[39m         primary_keys=([key_spec.to_proto() \u001b[38;5;28;01mfor\u001b[39;00m key_spec \u001b[38;5;129;01min\u001b[39;00m primary_key_spec]),\n\u001b[32m   (...)\u001b[39m\u001b[32m    221\u001b[39m         is_imported=is_imported,\n\u001b[32m    222\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     response_proto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCreateFeatureTable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m FeatureTable.from_proto(response_proto.feature_table)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/.venvs/databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster/lib/python3.12/site-packages/databricks/ml_features/_catalog_client/_catalog_client.py:186\u001b[39m, in \u001b[36mCatalogClient._call_endpoint\u001b[39m\u001b[34m(self, api, proto, req_context)\u001b[39m\n\u001b[32m    183\u001b[39m resolved_endpoint = \u001b[38;5;28mself\u001b[39m._resolve_url_params(endpoint, request_dict)\n\u001b[32m    184\u001b[39m response_proto = api.Response()\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call_endpoint(\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    187\u001b[39m     resolved_endpoint,\n\u001b[32m    188\u001b[39m     method,\n\u001b[32m    189\u001b[39m     request_dict,\n\u001b[32m    190\u001b[39m     response_proto,\n\u001b[32m    191\u001b[39m     req_context,\n\u001b[32m    192\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/.venvs/databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster/lib/python3.12/site-packages/databricks/ml_features/_catalog_client/_catalog_client.py:108\u001b[39m, in \u001b[36mCatalogClient.__init__.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, get_host_creds, feature_store_uri: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    Catalog client for the Feature Store client. Takes in an optional parameter to identify the remote workspace\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    for multi-workspace Feature Store.\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03m    :param feature_store_uri: An URI of the form ``databricks://<scope>.<prefix>`` that identifies the credentials\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m      of the intended Feature Store workspace. Throws an error if specified but credentials were not found.\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28mself\u001b[39m._get_host_creds = \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_store_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28mself\u001b[39m._local_host, \u001b[38;5;28mself\u001b[39m._local_workspace_id = \u001b[38;5;28mself\u001b[39m._get_local_workspace_info()\n\u001b[32m    110\u001b[39m     (\n\u001b[32m    111\u001b[39m         \u001b[38;5;28mself\u001b[39m._feature_store_workspace_host,\n\u001b[32m    112\u001b[39m         \u001b[38;5;28mself\u001b[39m._feature_store_workspace_id,\n\u001b[32m    113\u001b[39m     ) = \u001b[38;5;28mself\u001b[39m._get_feature_store_workspace_info(feature_store_uri)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/.venvs/databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster/lib/python3.12/site-packages/mlflow/utils/databricks_utils.py:819\u001b[39m, in \u001b[36mget_databricks_host_creds\u001b[39m\u001b[34m(server_uri)\u001b[39m\n\u001b[32m    816\u001b[39m     use_databricks_sdk = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    817\u001b[39m     databricks_auth_profile = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m819\u001b[39m config = \u001b[43m_get_databricks_creds_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config:\n\u001b[32m    822\u001b[39m     _fail_malformed_databricks_auth(profile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/.venvs/databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster/lib/python3.12/site-packages/mlflow/utils/databricks_utils.py:1108\u001b[39m, in \u001b[36m_get_databricks_creds_config\u001b[39m\u001b[34m(tracking_uri)\u001b[39m\n\u001b[32m   1105\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config.host:\n\u001b[32m-> \u001b[39m\u001b[32m1108\u001b[39m     \u001b[43m_fail_malformed_databricks_auth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/learning/databricks-ncaa-tournament-predictor/.venvs/databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster/lib/python3.12/site-packages/mlflow/utils/databricks_utils.py:682\u001b[39m, in \u001b[36m_fail_malformed_databricks_auth\u001b[39m\u001b[34m(uri)\u001b[39m\n\u001b[32m    667\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_in_databricks_model_serving_environment():\n\u001b[32m    668\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    669\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReading Databricks credential configuration in model serving failed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    670\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMost commonly, this happens because the model currently \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    680\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAdditional debug info: the MLflow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m was set to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    681\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    683\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReading Databricks credential configuration failed with MLflow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    684\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPlease ensure that the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdatabricks-sdk\u001b[39m\u001b[33m'\u001b[39m\u001b[33m PyPI library is installed, the tracking \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    685\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mURI is set correctly, and Databricks authentication is properly configured. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    686\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m can be either \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri_scheme\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    687\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(using \u001b[39m\u001b[33m'\u001b[39m\u001b[33mDEFAULT\u001b[39m\u001b[33m'\u001b[39m\u001b[33m authentication profile) or \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri_scheme\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m://\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[33mprofile\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    688\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mYou can configure Databricks authentication in several ways, for example by \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    689\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mspecifying environment variables (e.g. DATABRICKS_HOST + DATABRICKS_TOKEN) or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    690\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlogging in using \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdatabricks auth login\u001b[39m\u001b[33m'\u001b[39m\u001b[33m. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    691\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFor details on configuring Databricks authentication, please refer to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    692\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://docs.databricks.com/en/dev-tools/auth/index.html#unified-auth\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    693\u001b[39m )\n",
      "\u001b[31mMlflowException\u001b[39m: Reading Databricks credential configuration failed with MLflow tracking URI 'None'. Please ensure that the 'databricks-sdk' PyPI library is installed, the tracking URI is set correctly, and Databricks authentication is properly configured. The tracking URI can be either 'databricks' (using 'DEFAULT' authentication profile) or 'databricks://{profile}'. You can configure Databricks authentication in several ways, for example by specifying environment variables (e.g. DATABRICKS_HOST + DATABRICKS_TOKEN) or logging in using 'databricks auth login'. \nFor details on configuring Databricks authentication, please refer to 'https://docs.databricks.com/en/dev-tools/auth/index.html#unified-auth'."
     ]
    }
   ],
   "source": [
    "# Create the cleaned Kaggle datasets table\n",
    "from ncaa_tournament_predictor.jobs import kaggle_stats\n",
    "\n",
    "kaggle_stats.run_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c2a8ac258a4d669f5e1bac85e70043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the cleaned head-to-head table\n",
    "\n",
    "from ncaa_tournament_predictor.jobs import head_to_head\n",
    "\n",
    "head_to_head.run_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Datasets\n",
    "Combine data sets to create a dataset used for training an ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68312"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the \n",
    "from pyspark.sql.functions import rand\n",
    "\n",
    "from ncaa_tournament_predictor import transformation, tables\n",
    "\n",
    "\n",
    "team_stats = spark.read.table(tables.cleaned_kaggle_stats)\n",
    "head_to_head_results = spark.read.table(tables.cleaned_head_to_head_results)\n",
    "\n",
    "training_dataset = transformation.get_training_dataset(team_stats, head_to_head_results)\n",
    "training_dataset_sample = training_dataset.orderBy(rand()).limit(500)\n",
    "training_dataset.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration notebook\n",
    "This notebook is used for ad-hoc exploration of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run cells in this section to get your environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables using dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session for the Databricks compute environment\n",
    "from pyspark.sql import SparkSession\n",
    "from ncaa_tournament_predictor.databricks import get_databricks_spark_session\n",
    "\n",
    "# Explicit typing as SparkSession here to help out intellisense...DatabricksSession intellisense\n",
    "# isn't very good. In all my exploration so far, the DatabricksSession is compatible with the SparkSession\n",
    "spark: SparkSession = get_databricks_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all cells above this one to setup your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "This section contains various exploratory cells for getting data, transforming data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof-of-connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof-of-connectivity using an existing Databricks table\n",
    "\n",
    "hurricane_data_snippet = spark.sql(\"select * from object_computing.parametric_insurance.hurricane_data limit 10;\")\n",
    "hurricane_data_snippet.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hurricane_data_snippet_read = spark.read.table(\"object_computing.parametric_insurance.hurricane_data\")\n",
    "hurricane_data_snippet_read.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Men's college basketball schema setup\n",
    "Setup the schema/objects for the NCAA men's college basketball data to land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ncaa_mens_basketball schema\n",
    "spark.sql(\"create schema if not exists object_computing.ncaa_mens_basketball;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a volume for raw data\n",
    "\n",
    "spark.sql(\"create volume if not exists object_computing.ncaa_mens_basketball.raw_kaggle_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy raw data into the raw_kaggle_stats volume\n",
    "\n",
    "import os\n",
    "\n",
    "notebook_dir = os.path.abspath(os.getcwd())\n",
    "kaggle_dataset_path = os.path.abspath(\n",
    "    os.path.join(notebook_dir, \"../datasets/kaggle_ncaa_stats\")\n",
    ")\n",
    "volume_spark_path = \"/Volumes/object_computing/ncaa_mens_basketball/raw_kaggle_stats/\"\n",
    "\n",
    "\n",
    "for filename in os.listdir(kaggle_dataset_path):\n",
    "    spark.copyFromLocalToFs(\n",
    "        local_path=os.path.join(kaggle_dataset_path, filename),\n",
    "        dest_path=os.path.join(volume_spark_path, filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Kaggle stats dataset\n",
    "from pyspark.sql.functions import col, regexp_extract, Column, when\n",
    "\n",
    "def normalize_na(column: Column) -> Column:\n",
    "    return when(column == \"NA\", \"N/A\").otherwise(column)\n",
    "\n",
    "cleaned_ncaa_data = (\n",
    "    spark.read.format(\"csv\")\n",
    "        .options(header=True, inferSchema=True, mergeSchema=True)\n",
    "        .load(\"dbfs:/Volumes/object_computing/ncaa_mens_basketball/raw_kaggle_stats/\")\n",
    "        .withColumnsRenamed({\n",
    "            \"Team\": \"team\",\n",
    "            \"CONF\": \"conference\",\n",
    "            \"G\": \"games\",\n",
    "            \"W\": \"wins\",\n",
    "            \"ADJOE\": \"adjusted_offensive_efficiency\",\n",
    "            \"ADJDE\": \"adjusted_defensive_efficiency\",\n",
    "            \"BARTHAG\": \"power_rating\",\n",
    "            \"EFG_O\": \"effective_field_goal_percentage\",\n",
    "            \"EFG_D\": \"effective_field_goal_percentage_allowed\",\n",
    "            \"TOR\": \"turnover_rate\",\n",
    "            \"TORD\": \"caused_turnover_rate\",\n",
    "            \"ORB\": \"offensive_rebound_rate\",\n",
    "            \"DRB\": \"defensive_rebound_rate\",\n",
    "            \"FTR\": \"freethrows_attempted_rate\",\n",
    "            \"FTRD\": \"freethrows_allowed_rate\",\n",
    "            \"2P_O\": \"two_point_shooting_percentage\",\n",
    "            \"2P_D\": \"two_point_shooting_percentage_allowed\",\n",
    "            \"3P_O\": \"three_point_shooting_percentage\",\n",
    "            \"3P_D\": \"three_point_shooting_percentage_allowed\",\n",
    "            \"ADJ_T\": \"adjusted_tempo\",\n",
    "            \"WAB\": \"wins_above_bubble\",\n",
    "            \"SEED\": \"tournament_seed\",\n",
    "            \"POSTSEASON\": \"postseason_result\"\n",
    "        })\n",
    "        # Add source file information (including year)\n",
    "        .withColumn(\"source_filename\", col(\"_metadata.file_path\"))\n",
    "        .withColumn(\"year\", regexp_extract(col(\"_metadata.file_path\"), r\"cbb(\\d{4})\\.csv\", 1))\n",
    "        # Standardize N/A fields\n",
    "        .withColumn(\"postseason_result\", normalize_na(col(\"postseason_result\")))\n",
    "        .withColumn(\"tournament_seed\", normalize_na(col(\"tournament_seed\")))\n",
    "        # Drop RK column as it is only present in 2020 and 2025 datasets\n",
    "        .drop(\"RK\")\n",
    "        # Drop undocumented fields; assumed to be absolute 3-point numbers. Using percentage fields instead of absolute numbers\n",
    "        .drop(\"3PR\")\n",
    "        .drop(\"3PRD\")\n",
    "        # Drop undocumented fields; assumed to be some version of field goal %, but dropping due to not being in all datasets\n",
    "        .drop(\"EFGD_D\")\n",
    "        .drop(\"EFG%\")\n",
    "        .drop(\"EFGD%\")\n",
    ")\n",
    "cleaned_ncaa_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

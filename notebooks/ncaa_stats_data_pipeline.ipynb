{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCAA Stats Data Pipeline\n",
    "\n",
    "This \"pipeline\" is a notebook used to setup NCAA data in our Databricks sandbox. It's largely used as a workaround since we don't have access to DLT/jobs in our sandbox environment; For now, I'll just run the scripts manually like a peasant, but in real-life this could be converted to\n",
    "DLT pipelines, jobs, etc\n",
    "\n",
    "The steps in this notebook:\n",
    "1. Setup the initial schema for landing NCAA data\n",
    "1. Load raw data into Databricks\n",
    "1. Run ETL scripts to cleanup and transform data into a format suitable for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run cells in this section to get your environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup module autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables using dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session for the Databricks compute environment\n",
    "from pyspark.sql import SparkSession\n",
    "from ncaa_tournament_predictor.config import Config\n",
    "from ncaa_tournament_predictor.databricks import get_databricks_spark_session\n",
    "\n",
    "# Explicit typing as SparkSession here to help out intellisense...DatabricksSession intellisense\n",
    "# isn't very good. In all my exploration so far, the DatabricksSession is compatible with the SparkSession\n",
    "spark: SparkSession = get_databricks_spark_session(Config.databricks_profile())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all cells above this one to setup your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Setup\n",
    "\n",
    "Initial steps to create a Databricks schema for holding NCAA mens basketball data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ncaa_mens_basketball schema\n",
    "spark.sql(\"create schema if not exists object_computing.ncaa_mens_basketball;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Volumes\n",
    "Setup volumes for holding raw data files from various external data sources (CSVs, text files, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a volume for raw Kaggle stats data\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "raw_kaggle_stats_sql_object = volumes.as_sql_object(volumes.raw_kaggle_stats)\n",
    "spark.sql(f\"create volume if not exists {raw_kaggle_stats_sql_object}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy raw data into the raw_kaggle_stats volume\n",
    "\n",
    "import os\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "notebook_dir = os.path.abspath(os.getcwd())\n",
    "kaggle_dataset_path = os.path.abspath(\n",
    "    os.path.join(notebook_dir, \"../datasets/kaggle_ncaa_stats\")\n",
    ")\n",
    "\n",
    "for filename in os.listdir(kaggle_dataset_path):\n",
    "    spark.copyFromLocalToFs(\n",
    "        local_path=os.path.join(kaggle_dataset_path, filename),\n",
    "        dest_path=os.path.join(volumes.without_dbfs_protocol(volumes.raw_kaggle_stats), filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Kaggle stats dataset\n",
    "from ncaa_tournament_predictor import transformation, volumes\n",
    "\n",
    "raw_kaggle_stats = (\n",
    "    spark.read.format(\"csv\")\n",
    "        .options(header=True, inferSchema=True, mergeSchema=True)\n",
    "        .load(volumes.raw_kaggle_stats)\n",
    ")\n",
    "cleaned_ncaa_data = transformation.get_cleaned_kaggle_stats(raw_kaggle_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a volume for raw head-to-head data\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "spark.sql(f\"create volume if not exists {volumes.as_sql_object(volumes.raw_head_to_head)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy raw data into the raw_head_to_head volume\n",
    "\n",
    "import os\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "notebook_dir = os.path.abspath(os.getcwd())\n",
    "head_to_head_dataset_path = os.path.abspath(\n",
    "    os.path.join(notebook_dir, \"../datasets/kenpom_head_to_head\")\n",
    ")\n",
    "\n",
    "for filename in os.listdir(head_to_head_dataset_path):\n",
    "    spark.copyFromLocalToFs(\n",
    "        local_path=os.path.join(head_to_head_dataset_path, filename),\n",
    "        dest_path=os.path.join(volumes.without_dbfs_protocol(volumes.raw_head_to_head), filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup & Transformation\n",
    "Process the raw data, clean it up, and transform it for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cleaned Kaggle datasets table\n",
    "from ncaa_tournament_predictor.jobs import kaggle_stats\n",
    "\n",
    "kaggle_stats.run_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cleaned head-to-head table\n",
    "\n",
    "from ncaa_tournament_predictor.jobs import head_to_head\n",
    "\n",
    "head_to_head.run_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Game Prediction Model\n",
    "Combine data sets to create a dataset used for training an ML model. Then train and test the resulting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An equation for finding the optimal embedding size from a count of distinct items in the dataset\n",
    "import math\n",
    "\n",
    "def _get_embedding_output_size(distinct_data_size: int) -> int:\n",
    "    raw_output_size = 4 * math.sqrt(distinct_data_size)\n",
    "    return 2 ** round(math.log2(raw_output_size))\n",
    "\n",
    "print(f\"Embedding test of 379 items: {_get_embedding_output_size(379)}\")\n",
    "print(f\"Embedding test of 35 items: {_get_embedding_output_size(35)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the team stats and head-to-head results to build a training dataset\n",
    "from pyspark.sql.functions import rand\n",
    "\n",
    "from ncaa_tournament_predictor import transformation, tables\n",
    "\n",
    "\n",
    "team_stats = spark.read.table(tables.cleaned_kaggle_stats)\n",
    "head_to_head_results = spark.read.table(tables.cleaned_head_to_head_results)\n",
    "\n",
    "train_test_dataset = transformation.get_training_dataset(team_stats, head_to_head_results)\n",
    "training_dataset_sample = train_test_dataset.orderBy(rand()).limit(500)\n",
    "row_count = train_test_dataset.count()\n",
    "conference_count = team_stats.select(\"conference\").distinct().count()\n",
    "team_count = team_stats.select(\"team\").distinct().count()\n",
    "print(f\"Rows: {row_count}, distinct conferences: {conference_count}, distinct teams: {team_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data formatted for Tensorflow models\n",
    "from ncaa_tournament_predictor.tensorflow_models import game_prediction\n",
    "\n",
    "numeric_feature_columns = game_prediction.columns.individual_team_numeric_feature_columns\n",
    "# Get pre-processing layers derived from known data\n",
    "preprocessing_layers = game_prediction.get_data_preprocessing_layers(train_test_dataset, team_stats)\n",
    "features_preprocessor = game_prediction.get_features_preprocessor(\n",
    "    numeric_feature_columns=numeric_feature_columns,\n",
    "    team_vectorizer=preprocessing_layers.team_vectorizer,\n",
    "    conference_vectorizer=preprocessing_layers.conference_vectorizer,\n",
    "    stats_normalizer=preprocessing_layers.stats_normalizer,\n",
    ")\n",
    "training_data_preprocessor = game_prediction.get_training_data_preprocessor(\n",
    "    features_preprocessor=features_preprocessor,\n",
    ")\n",
    "\n",
    "# Split training and test data using arbitrary, but consistent seed for train/test split\n",
    "train_test_split_seed = 105\n",
    "raw_training_dataset, raw_test_dataset = train_test_dataset.randomSplit([0.8, 0.2], seed=train_test_split_seed)\n",
    "\n",
    "training_dataset = game_prediction.get_preprocessed_game_prediction_training_dataset(\n",
    "    raw_training_dataset,\n",
    "    numeric_feature_columns=numeric_feature_columns,\n",
    "    preprocessor=training_data_preprocessor,\n",
    ")\n",
    "test_dataset = game_prediction.get_preprocessed_game_prediction_training_dataset(\n",
    "    raw_test_dataset,\n",
    "    numeric_feature_columns=numeric_feature_columns,\n",
    "    preprocessor=training_data_preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the Tensors used for model input\n",
    "import pandas as pd\n",
    "\n",
    "np_array = []\n",
    "for tensor_idx, tensor in enumerate(training_dataset):\n",
    "    if tensor_idx > 25:\n",
    "        break\n",
    "    np_array.append(tensor)\n",
    "tensor_sample = pd.DataFrame.from_dict(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train the model\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "from ncaa_tournament_predictor.tensorflow_models import game_prediction\n",
    "\n",
    "# Compile model\n",
    "model = game_prediction.create_model(preprocessing_layers.team_vectorizer, preprocessing_layers.conference_vectorizer)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "model.fit(training_dataset, epochs=10, validation_data=test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../dist/neural_network_3_layer_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Differences Model\n",
    "Rather than look at raw feature values, calculate the difference between features for two teams (e.g. `t1_offensive_efficiency` - `t2_offensive_efficiency`) to\n",
    "see if that results in better predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get compared-features dataset\n",
    "\n",
    "from ncaa_tournament_predictor import queries, tables\n",
    "\n",
    "team_stats = spark.read.table(tables.cleaned_kaggle_stats)\n",
    "stats_differences_train_test_dataset = queries.get_stats_differences_training_dataset(spark)\n",
    "stats_differences_train_test_dataset_sample = stats_differences_train_test_dataset.sample(fraction=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data formatted for Tensorflow models\n",
    "from ncaa_tournament_predictor.tensorflow_models import game_prediction\n",
    "\n",
    "\n",
    "numeric_feature_columns = game_prediction.columns.stat_comparison_numeric_feature_columns\n",
    "# Get pre-processing layers derived from known data\n",
    "preprocessing_layers = game_prediction.get_data_preprocessing_layers(\n",
    "    stats_differences_train_test_dataset,\n",
    "    game_prediction.columns.stat_comparison_numeric_feature_columns,\n",
    "team_stats)\n",
    "features_preprocessor = game_prediction.get_features_preprocessor(\n",
    "    numeric_feature_columns=numeric_feature_columns,\n",
    "    team_vectorizer=preprocessing_layers.team_vectorizer,\n",
    "    conference_vectorizer=preprocessing_layers.conference_vectorizer,\n",
    "    stats_normalizer=preprocessing_layers.stats_normalizer,\n",
    ")\n",
    "training_data_preprocessor = game_prediction.get_training_data_preprocessor(\n",
    "    features_preprocessor=features_preprocessor\n",
    ")\n",
    "\n",
    "# Split training and test data using arbitrary, but consistent seed for train/test split\n",
    "train_test_split_seed = 105\n",
    "raw_training_dataset, raw_test_dataset = stats_differences_train_test_dataset.randomSplit([0.8, 0.2], seed=train_test_split_seed)\n",
    "\n",
    "training_dataset = game_prediction.get_preprocessed_game_prediction_training_dataset(\n",
    "    raw_training_dataset,\n",
    "    numeric_feature_columns=numeric_feature_columns,\n",
    "    preprocessor=training_data_preprocessor,\n",
    ")\n",
    "test_dataset = game_prediction.get_preprocessed_game_prediction_training_dataset(\n",
    "    raw_test_dataset,\n",
    "    numeric_feature_columns=numeric_feature_columns,\n",
    "    preprocessor=training_data_preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train the model\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "from ncaa_tournament_predictor.tensorflow_models import game_prediction\n",
    "\n",
    "# Compile model\n",
    "model = game_prediction.create_model(\n",
    "    game_prediction.columns.stat_comparison_numeric_feature_columns,\n",
    "    preprocessing_layers.team_vectorizer,\n",
    "    preprocessing_layers.conference_vectorizer\n",
    ")\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "model.fit(training_dataset, epochs=10, validation_data=test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../experimentation/models/team-comparison-nn-three-layer-dropout.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "import tensorflow as tf\n",
    "\n",
    "team_comparison_model = tf.keras.models.load_model(\"../experimentation/models/team-comparison-nn-three-layer-dropout.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "\n",
    "loss, accuracy = team_comparison_model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncaa_tournament_predictor import queries\n",
    "\n",
    "predicted_game_raw_df = queries.get_stats_differences(spark=spark, team_1=\"Mississippi\", team_2=\"Iowa St.\", college_season=2025)\n",
    "row_count = predicted_game_raw_df.count()\n",
    "if row_count != 1:\n",
    "    raise ValueError(f\"Expected exactly 1 row in prediction data but received {row_count} rows\")\n",
    "predicted_game_features = predicted_game_raw_df.first()\n",
    "predicted_game_inputs = features_preprocessor(predicted_game_features)\n",
    "batch_predicted_game_inputs = {key: tf.expand_dims(value, axis=0) for key, value in predicted_game_inputs.items()}\n",
    "\n",
    "prediction = team_comparison_model.predict(batch_predicted_game_inputs)\n",
    "probability_of_team_1_win = prediction[0][0]\n",
    "team_1 = predicted_game_features[\"team_1\"]\n",
    "team_2 = predicted_game_features[\"team_2\"]\n",
    "winner = team_1 if probability_of_team_1_win > 0.5 else team_2\n",
    "winning_probability = probability_of_team_1_win if team_1 == winner else (1.0 - probability_of_team_1_win)\n",
    "print(f\"{team_1} vs {team_2}: The model predicts {winner} will win with a {winning_probability} probability\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCAA Stats Data Pipeline\n",
    "\n",
    "This \"pipeline\" is a notebook used to setup NCAA data in our Databricks sandbox. It's largely used as a workaround since we don't have access to DLT/jobs in our sandbox environment; For now, I'll just run the scripts manually like a peasant, but in real-life this could be converted to\n",
    "DLT pipelines, jobs, etc\n",
    "\n",
    "The steps in this notebook:\n",
    "1. Setup the initial schema for landing NCAA data\n",
    "1. Load raw data into Databricks\n",
    "1. Run ETL scripts to cleanup and transform data into a format suitable for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run cells in this section to get your environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup module autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables using dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session for the Databricks compute environment\n",
    "from pyspark.sql import SparkSession\n",
    "from ncaa_tournament_predictor.config import Config\n",
    "from ncaa_tournament_predictor.databricks import get_databricks_spark_session\n",
    "\n",
    "# Explicit typing as SparkSession here to help out intellisense...DatabricksSession intellisense\n",
    "# isn't very good. In all my exploration so far, the DatabricksSession is compatible with the SparkSession\n",
    "spark: SparkSession = get_databricks_spark_session(Config.databricks_profile())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all cells above this one to setup your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Setup\n",
    "\n",
    "Initial steps to create a Databricks schema for holding NCAA mens basketball data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ncaa_mens_basketball schema\n",
    "spark.sql(\"create schema if not exists object_computing.ncaa_mens_basketball;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Volumes\n",
    "Setup volumes for holding raw data files from various external data sources (CSVs, text files, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a volume for raw Kaggle stats data\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "raw_kaggle_stats_sql_object = volumes.as_sql_object(volumes.raw_kaggle_stats)\n",
    "spark.sql(f\"create volume if not exists {raw_kaggle_stats_sql_object}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy raw data into the raw_kaggle_stats volume\n",
    "\n",
    "import os\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "notebook_dir = os.path.abspath(os.getcwd())\n",
    "kaggle_dataset_path = os.path.abspath(\n",
    "    os.path.join(notebook_dir, \"../datasets/kaggle_ncaa_stats\")\n",
    ")\n",
    "\n",
    "for filename in os.listdir(kaggle_dataset_path):\n",
    "    spark.copyFromLocalToFs(\n",
    "        local_path=os.path.join(kaggle_dataset_path, filename),\n",
    "        dest_path=os.path.join(volumes.without_dbfs_protocol(volumes.raw_kaggle_stats), filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Kaggle stats dataset\n",
    "from ncaa_tournament_predictor import transformation, volumes\n",
    "\n",
    "raw_kaggle_stats = (\n",
    "    spark.read.format(\"csv\")\n",
    "        .options(header=True, inferSchema=True, mergeSchema=True)\n",
    "        .load(volumes.raw_kaggle_stats)\n",
    ")\n",
    "cleaned_ncaa_data = transformation.get_cleaned_kaggle_stats(raw_kaggle_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a volume for raw head-to-head data\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "spark.sql(f\"create volume if not exists {volumes.as_sql_object(volumes.raw_head_to_head)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy raw data into the raw_head_to_head volume\n",
    "\n",
    "import os\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "notebook_dir = os.path.abspath(os.getcwd())\n",
    "head_to_head_dataset_path = os.path.abspath(\n",
    "    os.path.join(notebook_dir, \"../datasets/kenpom_head_to_head\")\n",
    ")\n",
    "\n",
    "for filename in os.listdir(head_to_head_dataset_path):\n",
    "    spark.copyFromLocalToFs(\n",
    "        local_path=os.path.join(head_to_head_dataset_path, filename),\n",
    "        dest_path=os.path.join(volumes.without_dbfs_protocol(volumes.raw_head_to_head), filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup & Transformation\n",
    "Process the raw data, clean it up, and transform it for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cleaned Kaggle datasets table\n",
    "from ncaa_tournament_predictor.jobs import kaggle_stats\n",
    "\n",
    "kaggle_stats.write_cleaned_kaggle_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cleaned head-to-head table\n",
    "\n",
    "from ncaa_tournament_predictor.jobs import head_to_head\n",
    "\n",
    "head_to_head.write_cleaned_head_to_head_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Datasets\n",
    "Combine data sets to create a dataset used for training an ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb48c7404855489086bd6d50172fe985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Row(year=2013, team='Troy', conference='SB', games=33, wins=12, adjusted_offensive_efficiency=97.3, adjusted_defensive_efficiency=107.5, power_rating=0.2416, effective_field_goal_percentage=45.3, effective_field_goal_percentage_allowed=51.0, turnover_rate=16.5, caused_turnover_rate=19.1, offensive_rebound_rate=30.7, defensive_rebound_rate=33.0, freethrows_attempted_rate=24.5, freethrows_allowed_rate=36.6, two_point_shooting_percentage=44.5, two_point_shooting_percentage_allowed=49.5, three_point_shooting_percentage=31.2, three_point_shooting_percentage_allowed=35.8, adjusted_tempo=61.1, wins_above_bubble=-16.6, postseason_result='N/A', tournament_seed=None, source_filename='dbfs:/Volumes/object_computing/ncaa_mens_basketball/raw_kaggle_stats/cbb2013.csv', game_date=datetime.date(2013, 1, 1), team_1='Yale', team_1_score=70, team_2='Iowa St.', team_2_score=80, team_1_won=False, winning_team='Iowa St.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ncaa_tournament_predictor import transformation\n",
    "\n",
    "training_dataset = transformation.get_training_dataset()\n",
    "training_dataset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databricks-ncaa-tournament-predictor-Y0X8jGzL-remote-databricks-cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

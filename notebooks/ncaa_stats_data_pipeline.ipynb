{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCAA Stats Data Pipeline\n",
    "\n",
    "This \"pipeline\" is a notebook used to setup NCAA data in our Databricks sandbox. It's largely used as a workaround since we don't have access to DLT/jobs in our sandbox environment; For now, I'll just run the scripts manually like a peasant, but in real-life this could be converted to\n",
    "DLT pipelines, jobs, etc\n",
    "\n",
    "The steps in this notebook:\n",
    "1. Setup the initial schema for landing NCAA data\n",
    "1. Load raw data into Databricks\n",
    "1. Run ETL scripts to cleanup and transform data into a format suitable for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run cells in this section to get your environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup module autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables using dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session for the Databricks compute environment\n",
    "from pyspark.sql import SparkSession\n",
    "from ncaa_tournament_predictor.config import Config\n",
    "from ncaa_tournament_predictor.databricks import get_databricks_spark_session\n",
    "\n",
    "# Explicit typing as SparkSession here to help out intellisense...DatabricksSession intellisense\n",
    "# isn't very good. In all my exploration so far, the DatabricksSession is compatible with the SparkSession\n",
    "spark: SparkSession = get_databricks_spark_session(Config.databricks_profile())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all cells above this one to setup your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Setup\n",
    "\n",
    "Initial steps to create a Databricks schema for holding NCAA mens basketball data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ncaa_mens_basketball schema\n",
    "spark.sql(\"create schema if not exists object_computing.ncaa_mens_basketball;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Volumes\n",
    "Setup volumes for holding raw data files from various external data sources (CSVs, text files, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a volume for raw Kaggle stats data\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "raw_kaggle_stats_sql_object = volumes.as_sql_object(volumes.raw_kaggle_stats)\n",
    "spark.sql(f\"create volume if not exists {raw_kaggle_stats_sql_object}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy raw data into the raw_kaggle_stats volume\n",
    "\n",
    "import os\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "notebook_dir = os.path.abspath(os.getcwd())\n",
    "kaggle_dataset_path = os.path.abspath(\n",
    "    os.path.join(notebook_dir, \"../datasets/kaggle_ncaa_stats\")\n",
    ")\n",
    "\n",
    "for filename in os.listdir(kaggle_dataset_path):\n",
    "    spark.copyFromLocalToFs(\n",
    "        local_path=os.path.join(kaggle_dataset_path, filename),\n",
    "        dest_path=os.path.join(volumes.without_dbfs_protocol(volumes.raw_kaggle_stats), filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Kaggle stats dataset\n",
    "from ncaa_tournament_predictor import transformation, volumes\n",
    "\n",
    "raw_kaggle_stats = (\n",
    "    spark.read.format(\"csv\")\n",
    "        .options(header=True, inferSchema=True, mergeSchema=True)\n",
    "        .load(volumes.raw_kaggle_stats)\n",
    ")\n",
    "cleaned_ncaa_data = transformation.get_cleaned_kaggle_stats(raw_kaggle_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a volume for raw head-to-head data\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "spark.sql(f\"create volume if not exists {volumes.as_sql_object(volumes.raw_head_to_head)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy raw data into the raw_head_to_head volume\n",
    "\n",
    "import os\n",
    "\n",
    "from ncaa_tournament_predictor import volumes\n",
    "\n",
    "notebook_dir = os.path.abspath(os.getcwd())\n",
    "head_to_head_dataset_path = os.path.abspath(\n",
    "    os.path.join(notebook_dir, \"../datasets/kenpom_head_to_head\")\n",
    ")\n",
    "\n",
    "for filename in os.listdir(head_to_head_dataset_path):\n",
    "    spark.copyFromLocalToFs(\n",
    "        local_path=os.path.join(head_to_head_dataset_path, filename),\n",
    "        dest_path=os.path.join(volumes.without_dbfs_protocol(volumes.raw_head_to_head), filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup & Transformation\n",
    "Process the raw data, clean it up, and transform it for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cleaned Kaggle datasets table\n",
    "from ncaa_tournament_predictor.jobs import kaggle_stats\n",
    "\n",
    "kaggle_stats.write_cleaned_kaggle_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cleaned head-to-head table\n",
    "\n",
    "from ncaa_tournament_predictor.jobs import head_to_head\n",
    "\n",
    "head_to_head.write_cleaned_head_to_head_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
